>"  
>node.js代码是单进程、单线程环境运行的，为了充分利用现代计算机多核的计算能力，node一般要进行多进程开发和部署

当我们执行node app.js时，启动了一个进程，但是这个进程并不是真正的只有一个线程，事实上node创建了很多线程（如异步io线程等）。  
但是我们所编写的代码只会运行在一个线程上，这就是node单线程运行环境的含义。  
单线程执行环境的好处是程序状态单一，不需要处理状态同步，死锁，上下文切换开销等多线程编程的问题，单线程程序更加高效。  
坏处是1无法充分利用多核CPU的性能；2.错误会引起整个应用退出；3.CPU密集操作将阻塞其他操作（异步IO调用发不出去，已完成的异步IO回调不能及时处理）  
node语言层面不支持创建线程，但是可以创建子进程。node提供3个与进程相关的模块：process，child_process, cluster.  

0. process模块  
  process对象是Node的一个全局对象，提供当前Node进程的信息。它可以在脚本的任意位置使用，不必通过require命令加载。该对象部署了EventEmitter接口。  
  process对象主要属性和方法：
  
    ~~~
    1. 标准输入/输出/错误
    process.stdin(fd0) 
    process.stdout(fd1)
    process.stderr(fd2)
    这3个属性对象实现了stream接口，可以通过pipe进行重定向
    fs.createReadStream('wow.txt').pipe(zlib.createGzip()).pipe(process.stdout);
    process.stdin.pipe(process.stdout)
    2. 参数和环境变量
    process.argv(命令行参数组成的数组,['node','/xx/xx/xx.js', 'arg1','arg2',...])
    process.execPath(node二进制文件绝对路径'/usr/local/bin/node')
    process.execArgv(node和js之间的参数 node --harmony script.js --version => '--harmony', argv属性数组跳过这个)
    process.env(shell环境变量，对象. 如process.evn.HOME用户主目录)
    3. 方法
    .chdir() 切换工作目录
    .cwd() 获取工作目录,注意与__dirname的区别,后者是脚本位置
    .exit() 退出进程，会触发exit事件
    .setgid() 设置组id
    .getgid() 获取组id
    .setuid() 设置用户uid
    .getuid() 获取用户uid
    .nextTick() 指定回调函数在本次event loop最后执行,注意与setTimeout(f,0)的区别，后者是下一个event loop的开头执行，所以nextTick先执行，而且因为nextTick不需要检查是否到期，更加高效。
    .on() 监听事件，'uncaughtException'未捕捉事件,'data'数据输入事件,'SIGINT'收到SIGINT信号事件(ctrl+c),'SIGTERM'收到SIGTERM信号事件,'exit'进程退出事件
    .kill(id, sig='SIGINT') 给指定进程发送信号
    
    ~~~

1. child_process模块  
  child_process模块用于创建子进程，将子进程运行结果存储在系统缓存中(最大200KB),等子进程结束后，通过回调函数返回子进程运行结果。
  
    ~~~
    .exec(command[, options][, callback]) 子进程执行bash,bash解析命令和参数，并执行
    .execFile(file[, args][, options][, callback]) 子进程执行特定程序，参数args数组传入，不会被bash解析，更加安全
    .spawn(command[, args][, options]) 子进程执行特定命令（其实和特定程序文件一个意思），参数args数组传入，不支持callback返回结果
    .fork(modulePath[, args][, options]) 子进程执行node模块（即node进程，执行模块代码），同时在父子进程间建立一个通信管道，用于通信。
    同样，对应的同步创建子进程的方法有
    .execSync(command[, options])
    .execFileSync(file[, args][, options])
    .spawnSync(command[, args][, options])
    同步版本和对应的异步版本用法基本一致，差别在于方法会阻塞直到子进程完全退出才返回，这会阻塞回调函数和信号处理函数的执行。前两个返回值是子进程stdout的输出；spawn返回一个完整信息的对象，包括子进程id，stdout/stderr输出，返回码等。
    异步版本返回ChildProcess对象，可以通过监听该对象的stdout/stderr/stdin属性对象的data事件来实时获取子进程执行结果。支持callback参数的，也可以通过callback回调函数的参数返回子进程stdout/stderr输出结果。
    对于上面的options参数，用于customize子进程如何被创建。说明如下：
    cwd <String> 工作目录，exec*默认null;spawn/fork默认父进程process.cwd()
    env <Object> 环境变量，exec*默认null;spawn/fork默认父进程process.env
    encoding <String> 编码方式，默认utf8。也可以传'buffer'，则stdout/stderr都是buffer对象
    maxBuffer 最大缓存区，默认200KB，溢出会导致进程退出
    timeout 超时时间，默认0；如果大于0，在子进程运行超过timeout微秒时发送killSignal指定的信号
    killSignal 默认'SIGTERM'
    uid 用户id
    gid 组id
    execPath fork特有,子进程使用的node实例（从这里往下都是fork和spawn特有的）
    silent <Boolean> fork特有，默认false，表示子进程的stdout/stderr/stdin直接pipe到父进程的stdout/stderr/stdin.如果为true，pipe到返回值child的stdout/stderr/stdin（即子进程的输出silent了）
    stdio <String> || <Array> fork如果指定,会覆盖slient选项,fork只支持Array参数。
        'pipe' <=> ['pipe','pipe','pipe'](默认，即相当于silent=false)
        'ignore' <=> ['ignore','ignore','ignore'](stdout/stderr/stdin直接打开/dev/null)
        'inherit' <=> [process.stdin, process.stdout, process.stderr](共享父进程stdout/stderr/stdin)
        Array中各项的意义是
        'pipe' pipe到返回值child的child.stdio数组，child.stdio[0-2]又可以通过child.stdin/stdout/stderr访问
        'ipc' 打开父子进程之间ipc通道，child的.on('message',f)/.send函数变得可用(只有JSON格式消息会触发'message'事件),一对父子进程最多只能建立一个ipc通道
        'ignore' 使node子进程直接在描述符上打开/dev/null,忽略所有输出
        <Stream> object 子进程共享这个流对象
        Positive integer 被当做父进程的文件描述符，子进程共享对应的文件流对象（转换成Steram object)
        null,undefined 使用默认值，即0-2使用'pipe',3以上使用'ignore'
    对于fork,必须指定1个'ipc'选项，如[0,1,2,'ipc']
    实验：
    cl.c 
    #include <stdio.h>
    int main()
    {
        int buf[128] = {0};
        scanf("%s", buf);
        printf("in cl: %s\n", buf);
        return 0;
    }
    $gcc cl.c -o cl //生成的cl程序从标准输入读字符串，标准输出打印出来
    script.js
    var child_process = require('child_process');
    var child = child_process.spawn('./cl', {stdio:['ipc',1,2]});
    child.send('abc123456');
    child.on('close', (code)=>{
        console.log("child process exit, code:" + code);
    });
    $node ./script.js
    in cl: "abc123456"
    child process exit, code:0
      detached <Boolean> 分离进程，对于non-windows，设置为true会使子进程成为一个新进程组头进程，建立一个新的会话；
    默认情况下，父进程会等待子进程退出。child.unref()会解除父进程事件循环对子进程的引用，使父进程可以独立于子进程退出。
    如果父子进程之间建立了IPC通道，则unref也不能使父进程自由退出；而且父进程退出，子进程也会跟着退出。
    所以如果想建立长期运行的子进程，父子进程之间不能建立IPC通道，即stdio为ignore或者指定某些流对象；inherit也可以长期运行，但是子进程会保持attach到父进程的控制终端。
    ~~~
    
2. cluster模块  
  child_process模块提供创建子进程，父子进程IPC通信等基础功能。对于一个多进程的网络程序，还涉及到子进程管理，负载均衡等问题。  
  这就是cluster模块要解决的问题。（最常见的多进程/线程程序就是网络程序，所以cluster模块和网络密切相关）    
  cluster模块用child_process.fork新建工作进程，所以master进程和worker进程之间可以通过IPC通道发送和接受server handler。  
  cluster提供共享端口，分发连接的方式：  
  A. master监听，将accept到的连接轮流（Round-Robin）发到各个相关子进程，子进程读取数据处理。这是默认方式   
  B. master创建监听socket，发送给相关子进程，子进程在该socket上监听和accept新连接。  
  理论上，第二种方式更加高性能，但事实上，各worker的负载是没有办法控制的，而且由于OS的调度策略问题，会使得连接集中在某几个worker中，而不是均衡分布。  
  另外，据说第二种方式还会存在惊群效应，即新的连接到达，会唤醒所有worker进程，但只有一个worker能accept到该连接，造成性能损耗。  
  在cluster中，没有路由逻辑，工作进程之间也没有共享状态，因此像登陆和会话这样的工作，不能设计成依赖内存里的对象。  
  另外，cluster不负责worker进程的管理，必须自行管理worker进程池中进程的创建和销毁。当没有worker进程时，现有连接会断开而且拒绝新的连接建立。
  
    ~~~
    示例代码：
    文件 server.js
    const cluster = require('cluster');
    const http = require('http');
    const numCPUs = require('os').cpus().length;
    
    if (cluster.isMaster) {
      // Fork workers.
      for (var i = 0; i < numCPUs; i++) {
        cluster.fork();
      }
    
      cluster.on('exit', (worker, code, signal) => {
        console.log(`worker ${worker.process.pid} died`);
      });
    } else {
      require('./app');
    }
    文件 app.js
    // Workers can share any TCP connection
    // In this case it is an HTTP server
    http.createServer((req, res) => {
      res.writeHead(200);
      res.end('hello world\n');
    }).listen(8000);
    ~~~
  实际工作文件app.js在编写的时候，基本不需要考虑是用在单线程环境中，还是集群worker里，非常便利。但是，对于集群，listen工作被放到了master里，所以对于  
  normal node process和 cluster worker，还是有一些差别的：  
  
    ~~~
    server.listen({fd:7}); 监听对象以消息形式从worker传递到master，所以监听的是master中而不是worker中，文件描述符7引用的对象。
    server.listen(handle); 显式监听handle会使得worker直接监听该handle，而不是通过master。
    server.listen(0); 只有第一个worker是真正的随机port，后面新建的worker都会直接使用该port。如果想使用特定端口，应该依据woker ID自行生成。
    ~~~
  下面罗列一下cluster模块提供的方法和事件：
    ~~~
    worker进程类：
    cluster.Worker 包含一个worker进程所需的所有公共信息和方法。在master中可以通过cluster.workers[id]变量获取；在worker中通过cluster.worker变量获取。一个worker中可能有多个server。
        方法：
        .disconnect() 断开worker中所有server的连接(server.close()，参见net模块disconnect方法)，等待所有server都已关闭(server的'close'触发)，然后关闭IPC
        .isConnected() 判断IPC是否连接着，fork之后true；'disconnect'触发之后false
        .isDead() worker是否结束
        .send(message[, sendHandle][, callback]) 通过IPC发送消息；在master中相当于ChildProcess.send，在worker中相当于process.send；
        变量：
        .exitedAfterDisconnect<Boolean> 标识worker是自愿退出还是意外退出，master中可以据此作出不同处理，重新spawn还是忽略。当调用.kill或者.disconnect时，被设置为true；否则为undefined。
        
    方法：
    .fork([env]) 创建一个新的worker，参数env是添加到worker进程的环境变量对象；返回cluster.Worker类实例；cluster模块触发'fork'<cluster.Worker>事件
    .isMaster() 判断当前进程是否为master进程，也可由process.env.NODE_UNIQUE_ID变量判断，如果是undefined，则为master
    .isWorker() 判断是否为Worker进程，和.isMaster()返回值相反
    .setupMaster([settings]) 修改fork的行为，只影响后建立的worker进程，不影响已经建立的worker。参数settings<Object>的配置项参见cluster.Worker变量。
        注意，.fork的参数env（添加到子进程的环境变量对象）不能通过setupMaster设定；调用.setupMaster之后，可以通过cluster.settings对象获取目前的fork设定
    .disconnect([callback]) 调用所有worker的disconnect方法，优雅退出。只能在master中调用。    
    变量：
    .settings<Object> 通过.fork()创建worker进程的配置，只在master进程中，且只有调用过.fork或者.setupMaster之后，这个变量才存在，否则为undefined. 默认值如下：
        .execArgv<String> 传递给node的参数，默认process.execArgv
        .exec<String> worker脚本路径，默认process.argv.slice(1)
        .args<Array> 传递给worker脚本的参数，默认process.argv.slice(2)
        .slient<Boolean> worker的标准/错误输出是否被输出到master的标准/错误输出,默认false
        .stdio<Array> 配置worker的stdio数组，覆盖slient参数，参见child_process.fork的参数
        .uid<Number> 配置worker进程所属的用户id
        .gid<Number> 配置worker进程所属的组id
        这个变量不建议手动设定或者修改，应该通过setupMaster方法修改。
    .schedulingPolicy 分发连接策略，只有两个选项可选cluster.SCHED_RR(默认)和SCHED_NONE，分别表示上述A和B方式。直接修改或者通过环境变量NODE_CLUSTER_SCHED_POLICY设定。且一旦调用了fork或者setupMaster就不可变。
    .worker<Object> 当前worker的cluster.Worker实例；master中不可用
    .workers<{id:Object}> 当前所有worker对象，以worker对象的id索引。当worker断开连接(disconnect)和退出(exit)时，对应的worker对象被移除。事件'disconnect'和'exit'达到的顺序不能保证，但在后一个到达之前肯定已经移除了。 
    事件:
    'fork' (<cluster.Worker>) fork时触发
    'disconnect' (<cluster.Worker>) 与worker之间的IPC断开时触发。worker优雅退出时(被信号kill或者调用disconnect)会触发这种断开。
    'exit' (<cluster.Worker>,<Code>,<Signal>) worker退出触发
    ~~~